# =============================================================================
# ARQUIVO: treinamentoRandomForest.py (VERS√ÉO FINAL OTIMIZADA)
# OBJETIVO: Treinar e otimizar um modelo RandomForestClassifier, aplicando
#           hiperpar√¢metros restritivos para combater o overfitting.
# =============================================================================

import pandas as pd
import joblib
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

class ModelTrainer:
    """
    Classe para treinar, otimizar e salvar um modelo RandomForestClassifier.
    """
    def __init__(self, preprocessor_path, random_state=42):
        self.random_state = random_state
        self.model = None
        try:
            self.preprocessor = joblib.load(preprocessor_path)
            print(f"‚úÖ Pr√©-processador '{preprocessor_path}' carregado com sucesso.")
        except FileNotFoundError:
            print(f"‚ùå Erro: Pr√©-processador '{preprocessor_path}' n√£o encontrado.")
            self.preprocessor = None

    def train(self, data, nota_de_corte=68):
        if self.preprocessor is None:
            return

        # 1. Preparar os dados
        X = data.drop(columns='Exam_Score')
        y = (data['Exam_Score'] >= nota_de_corte).astype(int)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=self.random_state, stratify=y)
        print(f"\n‚úÖ Dados brutos divididos para tarefa de CLASSIFICA√á√ÉO.")
        
        X_train_proc = self.preprocessor.transform(X_train)
        X_test_proc = self.preprocessor.transform(X_test)
        print("‚úÖ Dados de treino e teste transformados.")
        
        # 2. Otimiza√ß√£o e Treinamento com Foco em Regulariza√ß√£o
        print("\n--- Iniciando busca pelos melhores hiperpar√¢metros para evitar overfitting ---")

        # Grade de par√¢metros APRIMORADA para for√ßar o modelo a ser mais simples
        # e generalista, combatendo o v√≠cio em features espec√≠ficas.
        param_grid = {
            'n_estimators': [100, 200],
            # Profundidades menores evitam que as √°rvores se aprofundem demais e memorizem dados
            'max_depth': [5, 8, 10],
            # Exigir mais amostras por "folha" impede a cria√ß√£o de regras para casos muito espec√≠ficos
            'min_samples_leaf': [5, 10, 15],
            # Limitar as features por √°rvore aumenta a diversidade e robustez do modelo
            'max_features': ['sqrt', 'log2']
        }
        
        rf = RandomForestClassifier(random_state=self.random_state, n_jobs=-1, class_weight='balanced')
        
        # O GridSearchCV testar√° todas as combina√ß√µes e encontrar√° o melhor modelo
        grid_search = GridSearchCV(
            estimator=rf,
            param_grid=param_grid,
            cv=5,               # Valida√ß√£o cruzada com 5 folds para mais robustez
            scoring='roc_auc',  # M√©trica de otimiza√ß√£o
            verbose=2           # Mostra o progresso detalhado da busca
        )
        grid_search.fit(X_train_proc, y_train)
        
        print(f"\nMelhores par√¢metros encontrados: {grid_search.best_params_}")
        self.model = grid_search.best_estimator_
        
        # 3. Avaliar o modelo final otimizado
        self._evaluate(X_test_proc, y_test)
        
        # 4. Salvar o MODELO
        self._save_model()
        
    def _evaluate(self, X_test_proc, y_test):
        y_pred = self.model.predict(X_test_proc)
        print("\n--- Relat√≥rio de M√©tricas (Modelo Otimizado) ---")
        print(classification_report(y_test, y_pred, target_names=['Reprovado', 'Aprovado']))

    def _save_model(self):
        joblib.dump(self.model, '../pipelines/perf_rf_model.pkl')
        print("\nüíæ Modelo RandomForestClassifier otimizado salvo com sucesso em '../pipelines/perf_rf_model.pkl'!")

def load_data(filepath):
    try:
        df = pd.read_csv(filepath)
        print(f"‚úÖ Dataset '{filepath}' carregado com sucesso!")
        return df
    except FileNotFoundError:
        return None

if __name__ == "__main__":
    print("--- INICIANDO PROCESSO DE TREINAMENTO OTIMIZADO (Random Forest Classifier) ---")
    
    DATASET_PATH = '../datasets/StudentPerformanceFactors.csv'
    PREPROCESSOR_PATH = '../pipelines/perf_preprocess.pkl'
    
    dataframe = load_data(DATASET_PATH)
    
    if dataframe is not None:
        trainer = ModelTrainer(preprocessor_path=PREPROCESSOR_PATH)
        trainer.train(dataframe)
        print("\n--- PROCESSO DE TREINAMENTO CONCLU√çDO ---")
