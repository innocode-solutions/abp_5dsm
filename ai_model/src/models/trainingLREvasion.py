#==============================================================================
# Script para treinar um modelo de Regress√£o Log√≠stica para prever evas√£o escolar
# Objetivo: Treinar, avaliar e salvar o modelo conforme os crit√©rios de aceite.

import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix

class DropoutModelTrainer:
    """
    Classe para carregar dados e um pr√©-processador, e ent√£o treinar,
    avaliar e salvar um modelo de Regress√£o Log√≠stica para prever risco de evas√£o.
    """
    def __init__(self, preprocessor_path, random_state=42):
        self.random_state = random_state
        self.model = None
        # Carrega o pr√©-processador ao inicializar
        try:
            self.preprocessor = joblib.load(preprocessor_path)
            print(f"‚úÖ Pr√©-processador '{preprocessor_path}' carregado com sucesso.")
        except FileNotFoundError:
            print(f"‚ùå Erro: Pr√©-processador '{preprocessor_path}' n√£o encontrado.")
            print("‚û°Ô∏è Por favor, execute o script de cria√ß√£o do pr√©-processador primeiro.")
            self.preprocessor = None

    def train(self, data):
        """
        Executa o fluxo de treinamento usando o pr√©-processador j√° carregado.
        O target √© a coluna 'Dropout' (1 = Evadiu, 0 = Permaneceu).
        """
        if self.preprocessor is None:
            return

        # 1. Definir Target e Features
        if 'Dropout' not in data.columns:
            print("‚ùå Erro: A coluna 'Dropout' n√£o est√° no dataset.")
            return

        X = data.drop(columns=['Dropout'])
        y = data['Dropout']

        # 2. Dividir os dados
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=self.random_state, stratify=y
        )
        print(f"\n‚úÖ Dados divididos: {len(X_train)} para treino, {len(X_test)} para teste.")
        
        # 3. Aplicar o pr√©-processador
        X_train_proc = self.preprocessor.transform(X_train)
        X_test_proc = self.preprocessor.transform(X_test)
        print("‚úÖ Dados de treino e teste transformados com o pipeline carregado.")
        
        # 4. Treinamento do Modelo de Regress√£o Log√≠stica
        print("\n--- Treinando o modelo de Regress√£o Log√≠stica (Baseline) ---")
        self.model = LogisticRegression(
            random_state=self.random_state, 
            class_weight='balanced',
            max_iter=500
        )
        self.model.fit(X_train_proc, y_train)
        print("‚úÖ Modelo de Regress√£o Log√≠stica treinado com sucesso!")
        
        # 5. Avaliar o modelo final
        self._evaluate(X_test_proc, y_test)
        
        # 6. Salvar o MODELO
        self._save_model()
        
    def _evaluate(self, X_test_proc, y_test):
        """M√©todo privado para avaliar o modelo com as m√©tricas definidas nos crit√©rios de aceite."""
        y_pred = self.model.predict(X_test_proc)
        y_pred_proba = self.model.predict_proba(X_test_proc)[:, 1]  # Probabilidades da classe '1' (Evas√£o)
        
        # Calcular as m√©tricas solicitadas
        f1 = f1_score(y_test, y_pred)
        roc_auc = roc_auc_score(y_test, y_pred_proba)
        conf_matrix = confusion_matrix(y_test, y_pred)
        
        print("\n--- Relat√≥rio de M√©tricas (Crit√©rios de Aceite) ---")
        print(f"üîπ F1-Score: {f1:.4f}")
        print(f"üî∏ ROC-AUC: {roc_auc:.4f}")
        print("\nüìä Matriz de Confus√£o:")
        print(conf_matrix)

        # Verificar as M√©tricas de Sucesso
        print("\n--- Verifica√ß√£o das M√©tricas de Sucesso ---")
        f1_success = "‚úÖ Atingido" if f1 >= 0.70 else "‚ùå N√£o Atingido"
        roc_auc_success = "‚úÖ Atingido" if roc_auc >= 0.75 else "‚ùå N√£o Atingido"
        print(f"Meta F1-Score (‚â• 0,70): {f1_success}")
        print(f"Meta ROC-AUC (‚â• 0,75): {roc_auc_success}")

    def _save_model(self):
        joblib.dump(self.model, 'dropout_logreg_model.pkl')
        print("\nüíæ Modelo salvo com sucesso em 'dropout_logreg_model.pkl'!")

def load_data(filepath):
    try:
        df = pd.read_csv(filepath)
        print(f"‚úÖ Dataset '{filepath}' carregado com sucesso!")
        return df
    except FileNotFoundError:
        print(f"‚ùå Erro: Dataset '{filepath}' n√£o encontrado.")
        return None

if __name__ == "__main__":
    print("--- INICIANDO PROCESSO DE TREINAMENTO DE MODELO (Evas√£o de Alunos) ---")
    
    DATASET_PATH = '../datasets/xAPI_dropout.csv'
    PREPROCESSOR_PATH = '../pipelines/dropout_preprocess.pkl'
    
    dataframe = load_data(DATASET_PATH)
    
    if dataframe is not None:
        trainer = DropoutModelTrainer(preprocessor_path=PREPROCESSOR_PATH)
        trainer.train(dataframe)
        print("\n--- PROCESSO DE TREINAMENTO CONCLU√çDO ---")
