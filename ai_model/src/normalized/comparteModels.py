# =============================================================================
# ARQUIVO: 3_comparar_modelos.py
# OBJETIVO: Comparar os modelos de Classifica√ß√£o e Regress√£o para definir
#           a melhor abordagem para o MVP.
#           - Calcula m√©tricas apropriadas para cada modelo.
#           - Gera os gr√°ficos corretos para cada tarefa.
#           - Imprime uma documenta√ß√£o clara da decis√£o.
# =============================================================================

import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    f1_score, roc_auc_score, roc_curve,  # M√©tricas de Classifica√ß√£o
    mean_absolute_error, r2_score      # M√©tricas de Regress√£o
)

# --- CONFIGURA√á√ïES ---
DATASET_PATH = '../datasets/StudentPerformanceFactors.csv'
PREPROCESSOR_PATH = 'perf_preprocess.pkl'
LOGREG_MODEL_PATH = 'perf_logreg_model.pkl'
LINREG_MODEL_PATH = 'perf_reglin_model.pkl' # Corrigido o nome do arquivo
NOTA_DE_CORTE = 60
RANDOM_STATE = 42

# --- L√ìGICA PRINCIPAL ---
print("Iniciando a compara√ß√£o de modelos (Classifica√ß√£o vs. Regress√£o)...")

# Carregar tudo
try:
    df = pd.read_csv(DATASET_PATH)
    preprocessor = joblib.load(PREPROCESSOR_PATH)
    logreg_model = joblib.load(LOGREG_MODEL_PATH)
    linreg_model = joblib.load(LINREG_MODEL_PATH) # Corrigido o nome da vari√°vel
    print("‚úÖ Dados, pr√©-processador e modelos carregados.")
except FileNotFoundError:
    print("‚ùå ERRO: Modelos n√£o encontrados. Execute os scripts de treinamento primeiro.")
    exit()

# --- PREPARA√á√ÉO DOS DADOS ---
X = df.drop('Exam_Score', axis=1)

# Alvo para Regress√£o (a nota real)
y_reg = df['Exam_Score']
# Alvo para Classifica√ß√£o (Aprovado/Reprovado)
y_class = (df['Exam_Score'] >= NOTA_DE_CORTE).astype(int)

# Dividir dados para teste (usando o mesmo X e random_state para consist√™ncia)
_, X_test, _, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=RANDOM_STATE)
_, X_test, _, y_test_class = train_test_split(X, y_class, test_size=0.2, random_state=RANDOM_STATE, stratify=y_class)

# Pr√©-processar as features do conjunto de teste
X_test_proc = preprocessor.transform(X_test)
print(f"Dados de teste preparados com {len(X_test)} amostras.")


# --- 1. AVALIA√á√ÉO DO MODELO DE CLASSIFICA√á√ÉO (REGRESS√ÉO LOG√çSTICA) ---
print("\n--- Avaliando Regress√£o Log√≠stica (Classifica√ß√£o) ---")
y_pred_class = logreg_model.predict(X_test_proc)
y_proba_class = logreg_model.predict_proba(X_test_proc)[:, 1]

f1 = f1_score(y_test_class, y_pred_class)
roc_auc = roc_auc_score(y_test_class, y_proba_class)
print(f"üîπ F1-Score: {f1:.4f}")
print(f"üî∏ ROC-AUC:  {roc_auc:.4f}")


# --- 2. AVALIA√á√ÉO DO MODELO DE REGRESS√ÉO (REGRESS√ÉO LINEAR) ---
print("\n--- Avaliando Regress√£o Linear (Regress√£o) ---")
y_pred_reg = linreg_model.predict(X_test_proc)

mae = mean_absolute_error(y_test_reg, y_pred_reg)
r2 = r2_score(y_test_reg, y_pred_reg)
print(f"üîπ Erro M√©dio Absoluto (MAE): {mae:.2f} pontos")
print(f"üî∏ Coeficiente de Determina√ß√£o (R¬≤): {r2:.2f}")


# --- 3. GERA√á√ÉO DE GR√ÅFICOS ---
# Gr√°fico 1: Curva ROC para o modelo de Classifica√ß√£o
plt.figure(figsize=(10, 7))
fpr, tpr, _ = roc_curve(y_test_class, y_proba_class)
plt.plot(fpr, tpr, label=f"Regress√£o Log√≠stica (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--', label='Chance (AUC = 0.50)')
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('Curva ROC para Modelo de Classifica√ß√£o')
plt.legend()
plt.grid()
plt.savefig('grafico_curva_roc.png')
print("\n‚úÖ Gr√°fico da Curva ROC salvo como 'grafico_curva_roc.png'.")

# Gr√°fico 2: Gr√°fico de Res√≠duos para o modelo de Regress√£o
plt.figure(figsize=(10, 7))
residuals = y_test_reg - y_pred_reg
sns.scatterplot(x=y_pred_reg, y=residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Valores Previstos (Nota do Exame)')
plt.ylabel('Res√≠duos (Real - Previsto)')
plt.title('Gr√°fico de Res√≠duos para Modelo de Regress√£o')
plt.grid()
plt.savefig('grafico_residuos.png')
print("‚úÖ Gr√°fico de Res√≠duos salvo como 'grafico_residuos.png'.")


# --- 4. DOCUMENTA√á√ÉO DA DECIS√ÉO ---
print("\n\n" + "="*60)
print("--- DOCUMENTA√á√ÉO DA DECIS√ÉO DO BASELINE PARA O MVP ---")
print("="*60)

# Tabela comparativa
summary_data = {
    'Modelo': ['Regress√£o Log√≠stica', 'Regress√£o Linear'],
    'Tarefa': ['Classifica√ß√£o', 'Regress√£o'],
    'M√©trica Principal': ['ROC-AUC', 'MAE (Erro em Pontos)'],
    'Valor': [f"{roc_auc:.4f}", f"{mae:.2f}"],
    'M√©trica Secund√°ria': ['F1-Score', 'R¬≤'],
    'Valor ': [f"{f1:.4f}", f"{r2:.2f}"]
}
summary_df = pd.DataFrame(summary_data)
print("\n**Tabela Comparativa de M√©tricas:**")
print(summary_df.to_string(index=False))

print("\n\n**Qual abordagem escolher para o MVP?**")
print("""
A escolha do modelo n√£o depende apenas das m√©tricas, mas do **problema de neg√≥cio** que o MVP precisa resolver:

1.  **Escolha a REGRESS√ÉO LOG√çSTICA (Classifica√ß√£o) se a pergunta principal for:**
    "Quais alunos est√£o em risco de serem REPROVADOS?"
    - **Vantagem:** Fornece uma resposta direta e acion√°vel (Sim/N√£o), ideal para criar alertas e direcionar interven√ß√µes. √â mais simples para um MVP focado em a√ß√µes preventivas.

2.  **Escolha a REGRESS√ÉO LINEAR se a pergunta principal for:**
    "Qual ser√° a NOTA FINAL aproximada de cada aluno?"
    - **Vantagem:** Oferece uma vis√£o mais granular do desempenho. Permite diferenciar um aluno que pode tirar 58 de um que pode tirar 30, mesmo que ambos sejam "reprovados".

**Recomenda√ß√£o para o Baseline:**
Para um MVP cujo objetivo √© **"permitir a√ß√µes preventivas"**, a abordagem de **Classifica√ß√£o com a Regress√£o Log√≠stica** √© geralmente mais indicada. Ela responde √† pergunta de neg√≥cio mais cr√≠tica de forma direta e simples.
""")
print("="*60)