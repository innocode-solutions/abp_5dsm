#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para retreinar o pr√©-processador SEM o campo Previous_Scores
Isso evita vi√©s no modelo - o modelo n√£o deve usar notas anteriores para prever
"""

import sys
import pandas as pd
import joblib
from pathlib import Path
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Configura√ß√£o de caminhos
BASE_DIR = Path(__file__).resolve().parent.parent
DATASET_PATH = BASE_DIR / "datasets" / "StudentPerformanceFactors.csv"
PREPROCESSOR_PATH = BASE_DIR / "pipelines" / "perf_preprocess.pkl"

def main():
    print("=" * 60)
    print("RETREINANDO PR√â-PROCESSADOR SEM Previous_Scores")
    print("=" * 60)
    
    # Carregar dataset
    try:
        df = pd.read_csv(DATASET_PATH)
        print(f"‚úÖ Dataset carregado: {len(df)} registros")
    except FileNotFoundError:
        print(f"‚ùå Erro: Dataset n√£o encontrado em {DATASET_PATH}")
        sys.exit(1)
    
    # Separar features e target
    # REMOVER Previous_Scores e Exam_Score
    X = df.drop(['Exam_Score', 'Previous_Scores'], axis=1)
    y = df['Exam_Score']
    
    print(f"\n‚ö†Ô∏è Campos removidos: 'Exam_Score' (target), 'Previous_Scores' (vi√©s)")
    print(f"   Features restantes: {list(X.columns)}")
    
    # Definir features num√©ricas e categ√≥ricas
    numeric_features = [
        'Hours_Studied',
        'Sleep_Hours',
        'Attendance'
    ]
    
    categorical_features = [
        'Gender',
        'Parental_Education_Level',
        'Parental_Involvement',
        'School_Type',
        'Peer_Influence',
        'Extracurricular_Activities',
        'Learning_Disabilities',
        'Internet_Access',
        'Access_to_Resources',
        'Teacher_Quality',
        'Family_Income',
        'Motivation_Level',
        'Tutoring_Sessions',
        'Physical_Activity',
        'Distance_from_Home'
    ]
    
    print(f"\nüìä Features num√©ricas: {len(numeric_features)}")
    print(f"üìä Features categ√≥ricas: {len(categorical_features)}")
    
    # Criar pipelines
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
    ])
    
    # Criar ColumnTransformer
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ],
        remainder='drop'
    )
    
    # Treinar o pr√©-processador
    print("\nüîÑ Treinando o pr√©-processador...")
    preprocessor.fit(X)
    print("‚úÖ Pr√©-processador treinado com sucesso")
    
    # Salvar o pr√©-processador
    print(f"\nüíæ Salvando pr√©-processador em: {PREPROCESSOR_PATH}")
    joblib.dump(preprocessor, PREPROCESSOR_PATH)
    print("‚úÖ Pr√©-processador salvo com sucesso")
    
    # Testar o pr√©-processador
    print("\nüß™ Testando o pr√©-processador...")
    X_sample = X.head(5)
    X_processed = preprocessor.transform(X_sample)
    print(f"‚úÖ Teste bem-sucedido: {X_sample.shape[0]} amostras -> {X_processed.shape[1]} features processadas")
    
    print("\n" + "=" * 60)
    print("‚úÖ PROCESSO CONCLU√çDO COM SUCESSO!")
    print("=" * 60)
    print("\nüí° Pr√≥ximos passos:")
    print("   1. Retreine o modelo com: py models/train_performance_regression.py")
    print("   2. O modelo agora n√£o usar√° Previous_Scores, evitando vi√©s")

if __name__ == "__main__":
    main()

