#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script auxiliar para prediÃ§Ã£o de desempenho
Executado via child_process do Node.js
"""

import sys
import json
import math
import joblib
import pandas as pd
import shap
from pathlib import Path

# ConfiguraÃ§Ã£o de caminhos - agora relativo ao backend/src/ml
BASE_DIR = Path(__file__).resolve().parent.parent
PREPROCESSOR_PATH = BASE_DIR / "pipelines" / "perf_preprocess.pkl"
LOGREG_PATH = BASE_DIR / "pipelines" / "perf_logreg_model.pkl"
RF_PATH = BASE_DIR / "pipelines" / "perf_rf_model.pkl"
REGRESSION_MODEL_PATH = BASE_DIR / "pipelines" / "perf_regression_model.pkl"
DATA_PATH = BASE_DIR / "datasets" / "StudentPerformanceFactors.csv"

# Cache global para modelos e explainers
_models_cache = None
_preprocessor_cache = None
_explainers_cache = None
_X_train_proc_cache = None
_feature_names_cache = None

def load_artifacts():
    """Carrega modelos e explainers (com cache)"""
    global _models_cache, _preprocessor_cache, _explainers_cache
    global _X_train_proc_cache, _feature_names_cache
    
    # FORÃ‡AR RECARREGAMENTO para garantir que estamos usando o preprocessor atualizado
    # Comentado temporariamente para debug
    # if _models_cache is not None:
    #     return _preprocessor_cache, _models_cache, _explainers_cache, _X_train_proc_cache, _feature_names_cache
    
    try:
        _preprocessor_cache = joblib.load(PREPROCESSOR_PATH)
        _models_cache = {
            'RegressÃ£o LogÃ­stica': joblib.load(LOGREG_PATH),
            'Random Forest': joblib.load(RF_PATH)
        }
        
        df_train = pd.read_csv(DATA_PATH)
        print(f"ðŸ” DEBUG load_artifacts: Colunas no dataset: {list(df_train.columns)}", file=sys.stderr)
        print(f"ðŸ” DEBUG load_artifacts: Shape do dataset: {df_train.shape}", file=sys.stderr)
        
        # REMOVER Previous_Scores para corresponder ao preprocessor treinado
        X_train_ref = df_train.drop(['Exam_Score', 'Previous_Scores'], axis=1)
        print(f"ðŸ” DEBUG load_artifacts: Colunas apÃ³s remover Exam_Score e Previous_Scores: {list(X_train_ref.columns)}", file=sys.stderr)
        print(f"ðŸ” DEBUG load_artifacts: Shape apÃ³s remover: {X_train_ref.shape}", file=sys.stderr)
        
        # Verificar se o preprocessor tem feature_names_in_ e reordenar colunas
        if hasattr(_preprocessor_cache, 'feature_names_in_'):
            expected_features = list(_preprocessor_cache.feature_names_in_)
            print(f"ðŸ” DEBUG load_artifacts: Features esperadas pelo preprocessor: {expected_features}", file=sys.stderr)
            print(f"ðŸ” DEBUG load_artifacts: NÃºmero de features esperadas: {len(expected_features)}", file=sys.stderr)
            
            # Verificar se todas as features esperadas estÃ£o presentes
            missing_features = [f for f in expected_features if f not in X_train_ref.columns]
            if missing_features:
                print(f"âš ï¸ DEBUG load_artifacts: Features faltando: {missing_features}", file=sys.stderr)
            
            # Reordenar as colunas para corresponder Ã  ordem esperada pelo preprocessor
            X_train_ref = X_train_ref[expected_features]
            print(f"âœ… DEBUG load_artifacts: Colunas reordenadas para corresponder ao preprocessor", file=sys.stderr)
            print(f"ðŸ” DEBUG load_artifacts: Shape do X_train_ref antes da transformaÃ§Ã£o: {X_train_ref.shape}", file=sys.stderr)
        
        try:
            _X_train_proc_cache = _preprocessor_cache.transform(X_train_ref)
            print(f"âœ… DEBUG load_artifacts: TransformaÃ§Ã£o bem-sucedida. Shape processado: {_X_train_proc_cache.shape}", file=sys.stderr)
        except Exception as e:
            print(f"âŒ DEBUG load_artifacts: Erro na transformaÃ§Ã£o: {str(e)}", file=sys.stderr)
            print(f"âŒ DEBUG load_artifacts: Shape do X_train_ref: {X_train_ref.shape}", file=sys.stderr)
            print(f"âŒ DEBUG load_artifacts: Colunas do X_train_ref: {list(X_train_ref.columns)}", file=sys.stderr)
            raise
        _feature_names_cache = _preprocessor_cache.get_feature_names_out()
        
        # PrÃ©-calcula os explainers SHAP apenas para modelos compatÃ­veis
        # Os modelos de classificaÃ§Ã£o antigos podem ter sido treinados com preprocessor diferente
        _explainers_cache = {}
        for name, model in _models_cache.items():
            try:
                # Verificar se o modelo Ã© compatÃ­vel com o preprocessor atual
                # Tentando fazer uma prediÃ§Ã£o de teste
                test_pred = model.predict(_X_train_proc_cache[:1])
                # Se funcionou, criar o explainer
                _explainers_cache[name] = shap.Explainer(model, _X_train_proc_cache)
                print(f"âœ… DEBUG load_artifacts: Explainer criado para {name}", file=sys.stderr)
            except Exception as e:
                print(f"âš ï¸ DEBUG load_artifacts: NÃ£o foi possÃ­vel criar explainer para {name}: {str(e)}", file=sys.stderr)
                print(f"âš ï¸ DEBUG load_artifacts: Modelo {name} pode ter sido treinado com preprocessor diferente", file=sys.stderr)
                # Continuar sem esse explainer - usaremos apenas o modelo de regressÃ£o para explicaÃ§Ãµes
        
    except Exception as e:
        raise Exception(f"Erro ao carregar artefatos: {str(e)}")
    
    return _preprocessor_cache, _models_cache, _explainers_cache, _X_train_proc_cache, _feature_names_cache

def _get_grade_category(score: float) -> str:
    """Categoriza a nota em faixas de desempenho"""
    if score >= 90:
        return "EXCELENTE"
    elif score >= 80:
        return "MUITO BOM"
    elif score >= 70:
        return "BOM"
    elif score >= 60:
        return "REGULAR"
    else:
        return "INSUFICIENTE"

def predict_performance(student_data: dict, top_n=3):
    """Prediz desempenho acadÃªmico"""
    try:
        preprocessor, models, explainers, X_train_proc, feature_names = load_artifacts()
        
        df_student = pd.DataFrame([student_data])
        # Log para debug
        print(f"ðŸ” DEBUG: Colunas no student_data: {list(df_student.columns)}", file=sys.stderr)
        print(f"ðŸ” DEBUG: Shape do df_student: {df_student.shape}", file=sys.stderr)
        
        # Garantir que as colunas estÃ£o na ordem correta esperada pelo preprocessor
        if hasattr(preprocessor, 'feature_names_in_'):
            expected_features = list(preprocessor.feature_names_in_)
            print(f"ðŸ” DEBUG: Features esperadas pelo preprocessor: {expected_features}", file=sys.stderr)
            print(f"ðŸ” DEBUG: NÃºmero de features esperadas: {len(expected_features)}", file=sys.stderr)
            
            # Reordenar as colunas para corresponder Ã  ordem esperada pelo preprocessor
            missing_features = [f for f in expected_features if f not in df_student.columns]
            if missing_features:
                print(f"âš ï¸ DEBUG: Features faltando: {missing_features}", file=sys.stderr)
            
            # Garantir que todas as features esperadas estÃ£o presentes
            for feature in expected_features:
                if feature not in df_student.columns:
                    print(f"âš ï¸ DEBUG: Feature '{feature}' nÃ£o encontrada, adicionando com valor padrÃ£o", file=sys.stderr)
                    # Adicionar valor padrÃ£o baseado no tipo
                    if feature in ['Hours_Studied', 'Sleep_Hours', 'Attendance']:
                        df_student[feature] = 0  # Valor padrÃ£o numÃ©rico
                    else:
                        df_student[feature] = 'Unknown'  # Valor padrÃ£o categÃ³rico
            
            # Reordenar colunas para corresponder Ã  ordem esperada
            df_student = df_student[expected_features]
            print(f"ðŸ” DEBUG: Colunas apÃ³s reordenaÃ§Ã£o: {list(df_student.columns)}", file=sys.stderr)
        
        processed_student_data = preprocessor.transform(df_student)
        
        # Tenta usar o modelo de regressÃ£o primeiro (retorna nota real)
        # Se nÃ£o existir, usa o modelo de classificaÃ§Ã£o como fallback
        try:
            # PRIMEIRO: Extrair e verificar valores ANTES de fazer a prediÃ§Ã£o
            # Previous_Scores removido para evitar viÃ©s - o modelo nÃ£o deve usar notas anteriores
            hours_studied = float(student_data.get('Hours_Studied', 0) or 0)
            attendance = float(student_data.get('Attendance', 0) or 0)
            sleep_hours = float(student_data.get('Sleep_Hours', 0) or 0)
            
            # Log imediato dos valores recebidos
            print(f"ðŸ”ðŸ”ðŸ” VALORES RECEBIDOS (ANTES DA PREDIÃ‡ÃƒO):", file=sys.stderr)
            print(f"   Hours_Studied: {hours_studied}", file=sys.stderr)
            print(f"   Attendance: {attendance}", file=sys.stderr)
            print(f"   Sleep_Hours: {sleep_hours}", file=sys.stderr)
            print(f"   âš ï¸ Previous_Scores removido para evitar viÃ©s", file=sys.stderr)
            
            # O modelo foi treinado com casos extremos (tudo negativo â†’ 0, tudo positivo â†’ 100)
            # EntÃ£o ele deve aprender esses padrÃµes. NÃ£o precisamos de lÃ³gica de correÃ§Ã£o no backend.
            regression_model = joblib.load(REGRESSION_MODEL_PATH)
            # PrediÃ§Ã£o de regressÃ£o: retorna a nota real (0-100)
            predicted_score = float(regression_model.predict(processed_student_data)[0])
            print(f"ðŸ” PrediÃ§Ã£o do modelo (sem correÃ§Ãµes): {predicted_score:.2f}", file=sys.stderr)
            
            # Apenas garantir que estÃ¡ no range vÃ¡lido (0-100)
            predicted_score = max(0.0, min(100.0, predicted_score))
            
            # LOG FINAL para debug
            print(f"âœ… NOTA FINAL (modelo puro, sem correÃ§Ãµes): {predicted_score:.1f}", file=sys.stderr)
            
            # Calcular probabilidade de aprovaÃ§Ã£o usando funÃ§Ã£o sigmÃ³ide centrada em 60
            # Quanto mais longe de 60, maior a certeza (aprovaÃ§Ã£o ou reprovaÃ§Ã£o)
            # Quanto mais perto de 60, menor a certeza (zona de risco)
            # FunÃ§Ã£o sigmÃ³ide: quanto mais longe de 60, mais prÃ³ximo de 0 ou 1
            # Se nota = 60, probability = 0.5 (incerto)
            # Se nota = 70, probability â‰ˆ 0.88 (alta confianÃ§a em aprovaÃ§Ã£o)
            # Se nota = 50, probability â‰ˆ 0.12 (alta confianÃ§a em reprovaÃ§Ã£o)
            z = (predicted_score - 60) / 10  # Normaliza: cada 10 pontos = 1 unidade
            probability = 1 / (1 + math.exp(-z))  # FunÃ§Ã£o sigmÃ³ide
            
            # Calcular confidence baseada na distÃ¢ncia do limiar (60)
            # Confidence alta quando estÃ¡ longe de 60, mÃ©dia quando estÃ¡ perto
            distance_from_threshold = abs(predicted_score - 60)
            # Confidence mÃ¡xima (0.95) quando estÃ¡ 20+ pontos longe, mÃ­nima (0.6) quando estÃ¡ em 60
            confidence = min(0.95, max(0.6, 0.6 + (distance_from_threshold / 20) * 0.35))
            
            prediction_code = 1 if predicted_score >= 60 else 0
            use_regression = True
        except (FileNotFoundError, Exception) as e:
            # Fallback para modelo de classificaÃ§Ã£o
            use_regression = False
            model_name = 'Random Forest'
            model = models[model_name]
            prediction_code = int(model.predict(processed_student_data)[0])
            probability = float(model.predict_proba(processed_student_data)[0][1])
            # Mapear probabilidade para nota (mÃ©todo antigo melhorado)
            if probability < 0.3:
                predicted_score = float(probability / 0.3 * 40)
            elif probability < 0.7:
                predicted_score = float(40 + (probability - 0.3) / 0.4 * 30)
            else:
                predicted_score = float(70 + (probability - 0.7) / 0.3 * 30)
            predicted_score = max(0, min(100, predicted_score))
            # Para modelo de classificaÃ§Ã£o, confidence = probability (confianÃ§a do modelo)
            confidence = float(probability)
        
        # ExplicaÃ§Ã£o com SHAP (usa Random Forest para explicaÃ§Ã£o mesmo se regressÃ£o for usada)
        # Se o explainer do Random Forest nÃ£o estiver disponÃ­vel, usar o primeiro disponÃ­vel
        explanation_list = []
        shap_values_for_positive_class = None
        
        if explainers:
            # Tentar usar Random Forest primeiro, senÃ£o usar o primeiro disponÃ­vel
            explainer_model_name = 'Random Forest' if 'Random Forest' in explainers else list(explainers.keys())[0]
            explainer = explainers[explainer_model_name]
            
            try:
                shap_values = explainer(processed_student_data)
                
                try:
                    shap_values_for_positive_class = shap_values.values[0, :, 1]
                except IndexError:
                    shap_values_for_positive_class = shap_values.values[0]
            except Exception as e:
                print(f"âš ï¸ DEBUG: Erro ao calcular SHAP values: {str(e)}", file=sys.stderr)
                # Se nÃ£o conseguir calcular SHAP, usar lista vazia de explicaÃ§Ãµes
                shap_values_for_positive_class = None
        
            feature_impacts = pd.DataFrame(
                list(zip(feature_names, shap_values_for_positive_class)),
                columns=['feature', 'shap_value']
            ).sort_values(by='shap_value', key=abs, ascending=False).head(top_n)
            
            for _, row in feature_impacts.iterrows():
                feature_part = row['feature'].split('__')[1] if '__' in row['feature'] else row['feature']
                original_feature_name = next((col for col in student_data if feature_part.startswith(col)), feature_part)
                feature_value = student_data.get(original_feature_name, 'N/A')
                influence = "positiva" if row['shap_value'] > 0 else "negativa"
                explanation_list.append({
                    "feature": original_feature_name,
                    "value": feature_value,
                    "influence": influence
                })
        
        # predicted_score jÃ¡ foi calculado acima (do modelo de regressÃ£o ou mapeado do classificador)
        is_approved = predicted_score >= 60.0
        
        # Se nÃ£o usou regressÃ£o, confidence = probability (do modelo de classificaÃ§Ã£o)
        if not use_regression:
            confidence = float(probability)
        
        result = {
            "predicted_score": predicted_score,
            "confidence": float(confidence),
            "is_approved": is_approved,
            "approval_status": "APROVADO" if is_approved else "REPROVADO",
            "grade_category": _get_grade_category(predicted_score),
            "factors": explanation_list,
            "saved": False
        }
        
        # Imprime apenas o JSON para stdout
        print(json.dumps(result, ensure_ascii=False))
        
    except Exception as e:
        error_result = {
            "error": str(e),
            "type": type(e).__name__
        }
        print(json.dumps(error_result, ensure_ascii=False), file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    # Verificar se hÃ¡ argumentos de linha de comando para modo de teste
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        # Modo de teste com dados de exemplo
        test_data = {
            "Hours_Studied": 5,
            "Sleep_Hours": 2,
            "Distance_from_Home": "Near",
            "Attendance": 20,
            "Gender": "Male",
            "Parental_Education_Level": "None",
            "Parental_Involvement": "Low",
            "School_Type": "Public",
            "Peer_Influence": "Positive",
            "Extracurricular_Activities": "Yes",
            "Learning_Disabilities": "Yes",
            "Internet_Access": "Yes",
            "Access_to_Resources": "Poor",
            "Teacher_Quality": "Poor",
            "Family_Income": "Low",
            "Motivation_Level": "Low",
            "Tutoring_Sessions": "Yes",
            "Physical_Activity": "Low"
        }
        print("ðŸ§ª Modo de teste ativado", file=sys.stderr)
        predict_performance(test_data)
    else:
        # LÃª dados do stdin (modo normal quando chamado pelo Node.js)
        input_data = sys.stdin.read()
        
        if not input_data:
            error_result = {
                "error": "Nenhum dado recebido via stdin",
                "type": "ValueError"
            }
            print(json.dumps(error_result, ensure_ascii=False), file=sys.stderr)
            sys.exit(1)
        
        try:
            student_data = json.loads(input_data)
            predict_performance(student_data)
        except json.JSONDecodeError as e:
            error_result = {
                "error": f"Erro ao parsear JSON: {str(e)}",
                "type": "JSONDecodeError"
            }
            print(json.dumps(error_result, ensure_ascii=False), file=sys.stderr)
            sys.exit(1)
        except Exception as e:
            error_result = {
                "error": str(e),
                "type": type(e).__name__
            }
            print(json.dumps(error_result, ensure_ascii=False), file=sys.stderr)
            sys.exit(1)

